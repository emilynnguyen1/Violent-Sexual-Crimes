{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee986a01",
   "metadata": {},
   "source": [
    "# Predictive Analysis of Violent Sexual Crimes\n",
    "**Emily Nguyen, Kaylynn Francisco-Nelson, Angela Iraya**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4718ee16",
   "metadata": {},
   "source": [
    "## Data Description & Cleaning\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740cef14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DR_NO</th>\n",
       "      <th>Date Rptd</th>\n",
       "      <th>DATE OCC</th>\n",
       "      <th>TIME OCC</th>\n",
       "      <th>AREA</th>\n",
       "      <th>AREA NAME</th>\n",
       "      <th>Rpt Dist No</th>\n",
       "      <th>Part 1-2</th>\n",
       "      <th>Crm Cd</th>\n",
       "      <th>Crm Cd Desc</th>\n",
       "      <th>...</th>\n",
       "      <th>Time_Formatted</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Time_Category</th>\n",
       "      <th>Date_Rptd</th>\n",
       "      <th>DATE_OCC</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Reporting_Delay</th>\n",
       "      <th>Delay_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202013579</td>\n",
       "      <td>08/18/2020 12:00:00 AM</td>\n",
       "      <td>08/13/2020 12:00:00 AM</td>\n",
       "      <td>100</td>\n",
       "      <td>20</td>\n",
       "      <td>Olympic</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>860</td>\n",
       "      <td>BATTERY WITH SEXUAL CONTACT</td>\n",
       "      <td>...</td>\n",
       "      <td>1:00</td>\n",
       "      <td>1</td>\n",
       "      <td>Night (0-6)</td>\n",
       "      <td>2020-08-18</td>\n",
       "      <td>2020-08-13</td>\n",
       "      <td>2020</td>\n",
       "      <td>Aug</td>\n",
       "      <td>Thu</td>\n",
       "      <td>5</td>\n",
       "      <td>1-7 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211907205</td>\n",
       "      <td>04/01/2021 12:00:00 AM</td>\n",
       "      <td>02/22/2020 12:00:00 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1915</td>\n",
       "      <td>1</td>\n",
       "      <td>122</td>\n",
       "      <td>RAPE, ATTEMPTED</td>\n",
       "      <td>...</td>\n",
       "      <td>0:01</td>\n",
       "      <td>0</td>\n",
       "      <td>Night (0-6)</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>2020-02-22</td>\n",
       "      <td>2020</td>\n",
       "      <td>Feb</td>\n",
       "      <td>Sat</td>\n",
       "      <td>404</td>\n",
       "      <td>Over 1 year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221908151</td>\n",
       "      <td>04/12/2022 12:00:00 AM</td>\n",
       "      <td>10/01/2020 12:00:00 AM</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>821</td>\n",
       "      <td>SODOMY/SEXUAL CONTACT B/W PENIS OF ONE PERS TO...</td>\n",
       "      <td>...</td>\n",
       "      <td>0:01</td>\n",
       "      <td>0</td>\n",
       "      <td>Night (0-6)</td>\n",
       "      <td>2022-04-12</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>2020</td>\n",
       "      <td>Oct</td>\n",
       "      <td>Thu</td>\n",
       "      <td>558</td>\n",
       "      <td>Over 1 year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>201904093</td>\n",
       "      <td>01/02/2020 12:00:00 AM</td>\n",
       "      <td>01/02/2020 12:00:00 AM</td>\n",
       "      <td>2025</td>\n",
       "      <td>19</td>\n",
       "      <td>Mission</td>\n",
       "      <td>1901</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>RAPE, FORCIBLE</td>\n",
       "      <td>...</td>\n",
       "      <td>20:25</td>\n",
       "      <td>20</td>\n",
       "      <td>Evening (18-24)</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>2020</td>\n",
       "      <td>Jan</td>\n",
       "      <td>Thu</td>\n",
       "      <td>0</td>\n",
       "      <td>0-1 days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>210708216</td>\n",
       "      <td>04/29/2021 12:00:00 AM</td>\n",
       "      <td>05/01/2020 12:00:00 AM</td>\n",
       "      <td>1330</td>\n",
       "      <td>7</td>\n",
       "      <td>Wilshire</td>\n",
       "      <td>785</td>\n",
       "      <td>1</td>\n",
       "      <td>121</td>\n",
       "      <td>RAPE, FORCIBLE</td>\n",
       "      <td>...</td>\n",
       "      <td>13:30</td>\n",
       "      <td>13</td>\n",
       "      <td>Afternoon (12-18)</td>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>2020</td>\n",
       "      <td>May</td>\n",
       "      <td>Fri</td>\n",
       "      <td>363</td>\n",
       "      <td>1-12 months</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       DR_NO               Date Rptd                DATE OCC  TIME OCC  AREA  \\\n",
       "0  202013579  08/18/2020 12:00:00 AM  08/13/2020 12:00:00 AM       100    20   \n",
       "1  211907205  04/01/2021 12:00:00 AM  02/22/2020 12:00:00 AM         1    19   \n",
       "2  221908151  04/12/2022 12:00:00 AM  10/01/2020 12:00:00 AM         1    19   \n",
       "3  201904093  01/02/2020 12:00:00 AM  01/02/2020 12:00:00 AM      2025    19   \n",
       "4  210708216  04/29/2021 12:00:00 AM  05/01/2020 12:00:00 AM      1330     7   \n",
       "\n",
       "  AREA NAME  Rpt Dist No  Part 1-2  Crm Cd  \\\n",
       "0   Olympic         2014         2     860   \n",
       "1   Mission         1915         1     122   \n",
       "2   Mission         1988         1     821   \n",
       "3   Mission         1901         1     121   \n",
       "4  Wilshire          785         1     121   \n",
       "\n",
       "                                         Crm Cd Desc  ... Time_Formatted  \\\n",
       "0                        BATTERY WITH SEXUAL CONTACT  ...           1:00   \n",
       "1                                    RAPE, ATTEMPTED  ...           0:01   \n",
       "2  SODOMY/SEXUAL CONTACT B/W PENIS OF ONE PERS TO...  ...           0:01   \n",
       "3                                     RAPE, FORCIBLE  ...          20:25   \n",
       "4                                     RAPE, FORCIBLE  ...          13:30   \n",
       "\n",
       "   Hour      Time_Category   Date_Rptd    DATE_OCC  Year  Month DayOfWeek  \\\n",
       "0     1        Night (0-6)  2020-08-18  2020-08-13  2020    Aug       Thu   \n",
       "1     0        Night (0-6)  2021-04-01  2020-02-22  2020    Feb       Sat   \n",
       "2     0        Night (0-6)  2022-04-12  2020-10-01  2020    Oct       Thu   \n",
       "3    20    Evening (18-24)  2020-01-02  2020-01-02  2020    Jan       Thu   \n",
       "4    13  Afternoon (12-18)  2021-04-29  2020-05-01  2020    May       Fri   \n",
       "\n",
       "   Reporting_Delay  Delay_Category  \n",
       "0                5        1-7 days  \n",
       "1              404     Over 1 year  \n",
       "2              558     Over 1 year  \n",
       "3                0        0-1 days  \n",
       "4              363     1-12 months  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imports/setup\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../data/sexual_crimes_cleaned.csv\") # pre-cleaned data from phase 1\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59e7af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DR_NO', 'Date Rptd', 'DATE OCC', 'TIME OCC', 'AREA', 'AREA NAME',\n",
       "       'Rpt Dist No', 'Part 1-2', 'Crm Cd', 'Crm Cd Desc', 'Mocodes',\n",
       "       'Vict Age', 'Vict Sex', 'Vict Descent', 'Premis Cd', 'Premis Desc',\n",
       "       'Weapon Used Cd', 'Weapon Desc', 'Crm Cd 1', 'Crm Cd 2', 'Crm Cd 3',\n",
       "       'Crm Cd 4', 'Vict Descent Full', 'Vict Age Group', 'Time_Formatted',\n",
       "       'Hour', 'Time_Category', 'Date_Rptd', 'DATE_OCC', 'Year', 'Month',\n",
       "       'DayOfWeek', 'Reporting_Delay', 'Delay_Category'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# printing column names - including transformed cols from phase 1\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5447979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 12371\n",
      "Number of columns: 34\n"
     ]
    }
   ],
   "source": [
    "# get the number of rows and columns\n",
    "num_rows, num_cols = df.shape\n",
    "\n",
    "print(f\"Number of rows: {num_rows}\")\n",
    "print(f\"Number of columns: {num_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5da29343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Crm Cd                                        Crm Cd Desc  Case_Count\n",
      "10     860                        BATTERY WITH SEXUAL CONTACT        4134\n",
      "0      121                                     RAPE, FORCIBLE        3739\n",
      "4      815                SEXUAL PENETRATION W/FOREIGN OBJECT        1309\n",
      "3      810  SEX,UNLAWFUL(INC MUTUAL CONSENT, PENETRATION W...        1072\n",
      "5      820                                    ORAL COPULATION         718\n",
      "6      821  SODOMY/SEXUAL CONTACT B/W PENIS OF ONE PERS TO...         527\n",
      "7      822            HUMAN TRAFFICKING - COMMERCIAL SEX ACTS         456\n",
      "1      122                                    RAPE, ATTEMPTED         318\n",
      "2      760                    LEWD/LASCIVIOUS ACTS WITH CHILD          85\n",
      "9      840  BEASTIALITY, CRIME AGAINST NATURE SEXUAL ASSLT...           7\n",
      "8      830       INCEST (SEXUAL ACTS BETWEEN BLOOD RELATIVES)           6\n"
     ]
    }
   ],
   "source": [
    "crime_counts = (\n",
    "    df\n",
    "    .groupby(['Crm Cd', 'Crm Cd Desc'])\n",
    "    .size()\n",
    "    .reset_index(name='Case_Count')\n",
    "    .sort_values(by='Case_Count', ascending=False)\n",
    ")\n",
    "\n",
    "print(crime_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b83963",
   "metadata": {},
   "source": [
    "## Representation Comparison: Baseline vs Improved\n",
    "---\n",
    "We compare model behavior under 2 feature representations:\n",
    "- **Baseline**: Closest to Phase 1\n",
    "- **Improved**: Tranformations from our Feature Representation Audit\n",
    "\n",
    "We trained 3 models (Decision Tree, Random Forest, XGBoost), considering: \n",
    "- Accuracy, Precision, Recall, F1 (macro)\n",
    "- Fiarness metrics\n",
    "- Intepretability: permutation importance + SHAP for tree models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18fb03a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6624e16b",
   "metadata": {},
   "source": [
    "### Baseline Models\n",
    "In phase 1, we transformed some columns used in our model, including Delay_Cateogry, DayOfWeek, Vict Descent Full, Vict Age Group, and Time_Category. We used numerical features that were left untransformed, while the categorical features were one-hot encoded. \n",
    "\n",
    "We split the dataset 80/20 while preserving class distribution (stratify=y) to ensure each delay category is represented in both training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b2796b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target feature\n",
    "target = \"Delay_Category\"\n",
    "\n",
    "# features that we want to use for prediction\n",
    "numeric_features = [\n",
    "    \"Vict Age\", \"TIME OCC\", \"Hour\", \"Year\", \"Month\", \n",
    "    \"Part 1-2\", \"Rpt Dist No\" # new features we want to explore\n",
    "    ]\n",
    "categorical_features = [\n",
    "    \"DayOfWeek\", \"Vict Sex\", \"Vict Descent\", \"Vict Age Group\", \n",
    "    \"AREA NAME\", \"Premis Desc\", \"Crm Cd Desc\", \n",
    "    \"Weapon Desc\", \"Weapon Used Cd\",\n",
    "    # new features we want to explore (including categories made in phase 1)\n",
    "    \"Time_Category\", \"DayOfWeek\", \"DATE OCC\"\n",
    "]\n",
    "\n",
    "X = df[numeric_features + categorical_features]\n",
    "y = df[target].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350ef966",
   "metadata": {},
   "source": [
    "**Train/Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c87a8708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (9896, 19)  Test size: (2475, 19)\n"
     ]
    }
   ],
   "source": [
    "# train/test split before encoding\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \" Test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0952c092",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad1ff928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing: one-hot encode categorical, passthrough numerics\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", numeric_features),\n",
    "        (\"cat\", ohe, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14791c24",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n48 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py\", line 1131, in _hstack\n    check_array(X, accept_sparse=True, ensure_all_finite=False)\n    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Nov'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 655, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py\", line 1026, in fit_transform\n    return self._hstack(list(Xs), n_samples=n_samples)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py\", line 1135, in _hstack\n    raise ValueError(\n    ...<2 lines>...\n    ) from e\nValueError: For a sparse output, all columns should be a numeric or convertible to a numeric.\n\n--------------------------------------------------------------------------------\n192 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py\", line 1131, in _hstack\n    check_array(X, accept_sparse=True, ensure_all_finite=False)\n    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Aug'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 655, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py\", line 1026, in fit_transform\n    return self._hstack(list(Xs), n_samples=n_samples)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py\", line 1135, in _hstack\n    raise ValueError(\n    ...<2 lines>...\n    ) from e\nValueError: For a sparse output, all columns should be a numeric or convertible to a numeric.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Decision Tree\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtune_and_eval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDecisionTree\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mDecisionTreeClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclf__criterion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgini\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mentropy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclf__max_depth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclf__min_samples_leaf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclf__class_weight\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbalanced\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m)\u001b[49m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Random Forest\u001b[39;00m\n\u001b[1;32m     45\u001b[0m results\u001b[38;5;241m.\u001b[39mappend(tune_and_eval(\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomForest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     47\u001b[0m     RandomForestClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     X_train, y_train, X_test, y_test\n\u001b[1;32m     55\u001b[0m ))\n",
      "Cell \u001b[0;32mIn[33], line 16\u001b[0m, in \u001b[0;36mtune_and_eval\u001b[0;34m(model_name, estimator, param_grid, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[1;32m      7\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline([(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprep\u001b[39m\u001b[38;5;124m\"\u001b[39m, preprocess), (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclf\u001b[39m\u001b[38;5;124m\"\u001b[39m, estimator)])\n\u001b[1;32m      8\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[1;32m      9\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mpipe,\n\u001b[1;32m     10\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_grid,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 16\u001b[0m \u001b[43mgrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m best \u001b[38;5;241m=\u001b[39m grid\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[1;32m     18\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1051\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m   1046\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1047\u001b[0m     )\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m-> 1051\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1605\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1603\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1604\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1605\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_search.py:1028\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1023\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1024\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m   1026\u001b[0m     )\n\u001b[0;32m-> 1028\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m   1032\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_validation.py:505\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    499\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    501\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    504\u001b[0m     )\n\u001b[0;32m--> 505\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    508\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    509\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    515\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 240 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n48 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py\", line 1131, in _hstack\n    check_array(X, accept_sparse=True, ensure_all_finite=False)\n    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Nov'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 655, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py\", line 1026, in fit_transform\n    return self._hstack(list(Xs), n_samples=n_samples)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py\", line 1135, in _hstack\n    raise ValueError(\n    ...<2 lines>...\n    ) from e\nValueError: For a sparse output, all columns should be a numeric or convertible to a numeric.\n\n--------------------------------------------------------------------------------\n192 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py\", line 1131, in _hstack\n    check_array(X, accept_sparse=True, ensure_all_finite=False)\n    ~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/validation.py\", line 1053, in check_array\n    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_array_api.py\", line 757, in _asarray_with_order\n    array = numpy.asarray(array, order=order, dtype=dtype)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/pandas/core/generic.py\", line 2153, in __array__\n    arr = np.asarray(values, dtype=dtype)\nValueError: could not convert string to float: 'Aug'\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/model_selection/_validation.py\", line 859, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 655, in fit\n    Xt = self._fit(X, y, routed_params, raw_params=params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 589, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n                            ~~~~~~~~~~~~~~~~~~~~~~~~^\n        cloned_transformer,\n        ^^^^^^^^^^^^^^^^^^^\n    ...<5 lines>...\n        params=step_params,\n        ^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/joblib/memory.py\", line 326, in __call__\n    return self.func(*args, **kwargs)\n           ~~~~~~~~~^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/pipeline.py\", line 1540, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/utils/_set_output.py\", line 316, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/base.py\", line 1365, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py\", line 1026, in fit_transform\n    return self._hstack(list(Xs), n_samples=n_samples)\n           ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/compose/_column_transformer.py\", line 1135, in _hstack\n    raise ValueError(\n    ...<2 lines>...\n    ) from e\nValueError: For a sparse output, all columns should be a numeric or convertible to a numeric.\n"
     ]
    }
   ],
   "source": [
    "#   - Builds a pipeline: preprocessing (preprocess) + classifier (estimator)\n",
    "#   - Runs GridSearchCV with the given parameter grid and 5-fold CV, scoring by F1-macro\n",
    "#   - Fits the tuned model on the training data\n",
    "#   - Predicts labels on the test set\n",
    "#   - Returns a dictionary with: model name, best hyperparameters found, best cross-validation F1 score, test accuracy, test F1-macro, the trained best estimator itself\n",
    "def tune_and_eval(model_name, estimator, param_grid, X_train, y_train, X_test, y_test):\n",
    "    pipe = Pipeline([(\"prep\", preprocess), (\"clf\", estimator)])\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param_grid,\n",
    "        scoring=\"f1_macro\",\n",
    "        cv=5,\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    grid.fit(X_train, y_train)\n",
    "    best = grid.best_estimator_\n",
    "    y_pred = best.predict(X_test)\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"best_params\": grid.best_params_\n",
    "        ,\n",
    "        \"cv_f1_macro\": grid.best_score_,\n",
    "        \"test_accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"test_f1_macro\": f1_score(y_test, y_pred, average=\"macro\"),\n",
    "        \"estimator\": best\n",
    "    }\n",
    "\n",
    "results = []\n",
    "\n",
    "# Decision Tree\n",
    "results.append(tune_and_eval(\n",
    "    \"DecisionTree\",\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    {\n",
    "        \"clf__criterion\": [\"gini\", \"log_loss\"],\n",
    "        \"clf__max_depth\": [5, 10, 20, None],\n",
    "        \"clf__min_samples_leaf\": [1, 5, 10, 50],\n",
    "        \"clf__max_features\": [None, \"sqrt\", \"log2\"],\n",
    "        \"clf__class_weight\": [None, \"balanced\"],\n",
    "    },\n",
    "    X_train, y_train, X_test, y_test\n",
    "))\n",
    "\n",
    "# Random Forest\n",
    "results.append(tune_and_eval(\n",
    "    \"RandomForest\",\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    {\n",
    "        \"clf__n_estimators\": [300],\n",
    "        \"clf__max_depth\": [None, 8, 16],\n",
    "        \"clf__min_samples_leaf\": [1, 10, 50],\n",
    "        \"clf__class_weight\": [None, \"balanced_subsample\"],\n",
    "    },\n",
    "    X_train, y_train, X_test, y_test\n",
    "))\n",
    "\n",
    "# XGBoost\n",
    "results.append(tune_and_eval(\n",
    "    \"XGBoost\",\n",
    "    XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    {\n",
    "        \"clf__n_estimators\": [100, 200, 300],\n",
    "        \"clf__max_depth\": [4, 6, 8],\n",
    "        \"clf__learning_rate\": [0.01, 0.1, 0.3],\n",
    "        \"clf__subsample\": [0.8, 1.0],\n",
    "        \"clf__colsample_bytree\": [0.8, 1.0],\n",
    "        \n",
    "        # use this instead if XGBoost is performing quickly enough to add more params\n",
    "        # \"clf__n_estimators\": [200, 400],\n",
    "        # \"clf__max_depth\": [4, 6, 8],\n",
    "        # \"clf__learning_rate\": [0.01, 0.05, 0.1],\n",
    "        # \"clf__subsample\": [0.7, 0.8, 1.0],\n",
    "        # \"clf__colsample_bytree\": [0.7, 0.8, 1.0],\n",
    "        # \"clf__gamma\": [0, 1, 5],\n",
    "        # \"clf__reg_lambda\": [1, 5, 10],\n",
    "        # \"clf__reg_alpha\": [0, 0.1, 1],\n",
    "    },\n",
    "    X_train, y_train, X_test, y_test\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038f3a0d",
   "metadata": {},
   "source": [
    "### Transformations\n",
    "**Previously Transformed Columns from Phase 1 include:**\n",
    "- Vict Descent Full\n",
    "- Vict Age Group\n",
    "- Time_Formatted\n",
    "- Hour\n",
    "- Time_Category\n",
    "- Year\n",
    "- Month\n",
    "- DayOfWeek\n",
    "- Reporting_Delay\n",
    "- Delay_Category"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c8f49e",
   "metadata": {},
   "source": [
    "**Transforming \"Premis Desc\"**\n",
    "- \"Premis_Category\": Grouped bins by type of premises (e.g., \"Residential\", \"Commerical/Business\", etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8d33cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premis_Category\n",
      "Residential                 6377\n",
      "Public Outdoor              2835\n",
      "Vehicle/Transportation      1365\n",
      "Institutional                683\n",
      "Other/Unknown                524\n",
      "Commercial/Business          447\n",
      "Entertainment/Recreation     116\n",
      "Industrial/Construction       24\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Transform \"Premis Desc\" into high-level categories\n",
    "desc_upper = df[\"Premis Desc\"].str.upper()\n",
    "\n",
    "conditions = [\n",
    "    # Residential\n",
    "    desc_upper.str.contains(r'SINGLE FAMILY DWELLING|MULTI-UNIT DWELLING|CONDOMINIUM|TOWNHOUSE|MOBILE HOME|OTHER RESIDENCE|FRAT HOUSE|DORMITORY|SRO|GROUP HOME|HOTEL|MOTEL|TRANSITIONAL HOUSING|FOSTER HOME|VACATION RENTAL', na=False),\n",
    "\n",
    "    # Vehicle/Transportation\n",
    "    desc_upper.str.contains(r'VEHICLE|AUTO|CAR|TRUCK|BUS|MTA|METROLINK|GREYHOUND|PARKING LOT|PARKING GARAGE|DRIVEWAY|GARAGE|CARPORT|TOW YARD|BUS STOP|TRAIN DEPOT|TERMINAL|STATION', na=False),\n",
    "\n",
    "    # Public Outdoor\n",
    "    desc_upper.str.contains(r'STREET|SIDEWALK|HIGHWAY|ROAD|ALLEY|FREEWAY|UNDERPASS|PARK|PLAYGROUND|BEACH|PIER|RIVER BED|VACANT LOT', na=False),\n",
    "\n",
    "    # Commercial/Business\n",
    "    desc_upper.str.contains(r'RESTAURANT|FAST FOOD|COFFEE SHOP|BAR|NIGHT CLUB|TAVERN|STORE|MARKET|MALL|SHOPPING|RETAIL|DEPARTMENT|DRUG STORE|LIQUOR|OFFICE|BUSINESS|BANK|PAWN SHOP|SWAP MEET|GAS STATION|MINI-MART|AUTO REPAIR|CAR WASH', na=False),\n",
    "\n",
    "    # Institutional\n",
    "    desc_upper.str.contains(r'SCHOOL|COLLEGE|UNIVERSITY|PRESCHOOL|DAY CARE|HOSPITAL|MEDICAL|CLINIC|NURSING|HOSPICE|METHADONE|CHURCH|SYNAGOGUE|TEMPLE|LIBRARY|MUSEUM|GOVERNMENT|POLICE|DETENTION|JAIL', na=False),\n",
    "\n",
    "    # Entertainment/Recreation\n",
    "    desc_upper.str.contains(r'ENTERTAINMENT|COMEDY CLUB|THEATRE|MOVIE|BOWLING|ARCADE|SPORTS|ARENA|STADIUM|GYM|SPA|POOL|SKATEBOARD|SEX ORIENTED|STRIP CLUB|MASSAGE PARLOR', na=False),\n",
    "\n",
    "    # Industrial/Construction\n",
    "    desc_upper.str.contains(r'CONSTRUCTION|FACTORY|WAREHOUSE|MANUFACTURING', na=False),\n",
    "\n",
    "    # Other/Unknown\n",
    "    desc_upper.str.contains(r'UNKNOWN|OTHER PREMISE|OTHER BUSINESS|OTHER/OUTSIDE', na=False)\n",
    "]\n",
    "\n",
    "choices = [\n",
    "    \"Residential\",\n",
    "    \"Vehicle/Transportation\",\n",
    "    \"Public Outdoor\",\n",
    "    \"Commercial/Business\",\n",
    "    \"Institutional\",\n",
    "    \"Entertainment/Recreation\",\n",
    "    \"Industrial/Construction\",\n",
    "    \"Other/Unknown\"\n",
    "]\n",
    "\n",
    "df[\"Premis_Category\"] = np.select(conditions, choices, default=\"Other/Unknown\")\n",
    "\n",
    "print(df[\"Premis_Category\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb040237",
   "metadata": {},
   "source": [
    "**Transforming \"Weapon Desc\"**\n",
    "- \"Weapon_Category\": Consolidated individual weapon descriptions into higher-level categories to simplify interpretation and distinguish between weapon use vs. no weapon use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7e068af4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['STRONG-ARM (HANDS, FIST, FEET OR BODILY FORCE)', nan,\n",
       "       'UNKNOWN WEAPON/OTHER WEAPON', 'HAND GUN', 'PHYSICAL PRESENCE',\n",
       "       'OTHER KNIFE', 'VERBAL THREAT', 'KNIFE WITH BLADE 6INCHES OR LESS',\n",
       "       'CLUB/BAT', 'BOTTLE', 'UNKNOWN FIREARM', 'SEMI-AUTOMATIC PISTOL',\n",
       "       'OTHER FIREARM', 'STICK', 'FOLDING KNIFE',\n",
       "       'KNIFE WITH BLADE OVER 6 INCHES IN LENGTH', 'KITCHEN KNIFE',\n",
       "       'ROPE/LIGATURE', 'AUTOMATIC WEAPON/SUB-MACHINE GUN',\n",
       "       'BLUNT INSTRUMENT', 'TIRE IRON', 'SIMULATED GUN',\n",
       "       'PIPE/METAL PIPE', 'FIXED OBJECT', 'SEMI-AUTOMATIC RIFLE',\n",
       "       'HAMMER', 'MACE/PEPPER SPRAY', 'AXE', 'REVOLVER',\n",
       "       'CAUSTIC CHEMICAL/POISON', 'SCISSORS', 'OTHER CUTTING INSTRUMENT',\n",
       "       'STUN GUN', 'LIQUOR/DRUGS', 'TOY GUN',\n",
       "       'HECKLER & KOCH 93 SEMIAUTOMATIC ASSAULT RIFLE', 'BOW AND ARROW',\n",
       "       'MACHETE', 'DIRK/DAGGER', 'RAZOR BLADE', 'SCALDING LIQUID',\n",
       "       'HECKLER & KOCH 91 SEMIAUTOMATIC ASSAULT RIFLE',\n",
       "       'ROCK/THROWN OBJECT', 'BELT FLAILING INSTRUMENT/CHAIN'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at unique values in \"Weapon Desc\"\n",
    "df['Weapon Desc'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a4b5b09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weapon_Category\n",
      "No Weapon, Physical Force     11675\n",
      "Chemical, Explosive, Other      427\n",
      "Firearm                         134\n",
      "Knife, Sharp Object             106\n",
      "Blunt Object                     29\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create uppercase version to make matching easier\n",
    "desc_upper = df[\"Weapon Desc\"].str.upper()\n",
    "\n",
    "# Define boolean masks for each category\n",
    "conditions = [\n",
    "    # No Weapon / Physical Force\n",
    "    desc_upper.isna() | desc_upper.str.contains(r'STRONG-ARM|PHYSICAL PRESENCE|VERBAL THREAT', na=False),\n",
    "    \n",
    "    # Firearm\n",
    "    desc_upper.str.contains(r'HAND GUN|REVOLVER|SEMI-AUTOMATIC|AUTOMATIC|OTHER FIREARM|UNKNOWN FIREARM|SIMULATED GUN|TOY GUN|HECKLER|RIFLE', na=False),\n",
    "    \n",
    "    # Knife / Sharp Object\n",
    "    desc_upper.str.contains(r'KNIFE|DIRK|DAGGER|MACHETE|RAZOR|SCISSORS|CUTTING', na=False),\n",
    "    \n",
    "    # Blunt Object\n",
    "    desc_upper.str.contains(r'CLUB|BAT|STICK|PIPE|TIRE IRON|HAMMER|ROCK|BELT|CHAIN|BLUNT|FIXED OBJECT|BOTTLE', na=False),\n",
    "    \n",
    "    # Chemical / Explosive / Other\n",
    "    desc_upper.str.contains(r'MACE|PEPPER SPRAY|CAUSTIC|POISON|SCALDING|LIQUOR|DRUGS|BOW|ARROW|OTHER WEAPON|ROPE|LIGATURE|AXE|STUN GUN', na=False)\n",
    "]\n",
    "\n",
    "# Define labels corresponding to the above conditions\n",
    "choices = [\n",
    "    \"No Weapon, Physical Force\",\n",
    "    \"Firearm\",\n",
    "    \"Knife, Sharp Object\",\n",
    "    \"Blunt Object\",\n",
    "    \"Chemical, Explosive, Other\"\n",
    "]\n",
    "\n",
    "# Apply transformation\n",
    "df[\"Weapon_Category\"] = np.select(conditions, choices, default=\"Other/Unknown\")\n",
    "\n",
    "# Verify transformation\n",
    "print(df[\"Weapon_Category\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14626f10",
   "metadata": {},
   "source": [
    "### Improved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "85cc472e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target feature\n",
    "target = \"Delay_Category\"\n",
    "\n",
    "# features that we want to use for prediction\n",
    "numeric_features = [\n",
    "    \"Hour\", \"Year\", \"Month\", \n",
    "    \"Part 1-2\", \"Rpt Dist No\"\n",
    "]\n",
    "categorical_features = [\n",
    "    \"Vict Sex\", \"Vict Descent Full\", \"Vict Age Group\", \n",
    "    \"AREA NAME\", \"Premis_Category\",\n",
    "    \"Crm Cd Desc\", \"Weapon_Category\",\n",
    "    \"DayOfWeek\", \"Time_Category\", \n",
    "]\n",
    "\n",
    "X = df[numeric_features + categorical_features]\n",
    "y = df[target].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6f732f",
   "metadata": {},
   "source": [
    "**Train/Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d69574c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (9896, 14)  Test size: (2475, 14)\n"
     ]
    }
   ],
   "source": [
    "# train/test split before encoding\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \" Test size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39b839d",
   "metadata": {},
   "source": [
    "**Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9a4b7982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing: one-hot encode categorical, passthrough numerics\n",
    "ohe = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", \"passthrough\", numeric_features),\n",
    "        (\"cat\", ohe, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8c6bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "improved_results = []\n",
    "\n",
    "# Decision Tree\n",
    "improved_results.append(tune_and_eval(\n",
    "    \"DecisionTree\",\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    {\n",
    "        \"clf__criterion\": [\"gini\", \"log_loss\"],\n",
    "        \"clf__max_depth\": [5, 10, 20, None],\n",
    "        \"clf__min_samples_leaf\": [1, 5, 10, 50],\n",
    "        \"clf__max_features\": [None, \"sqrt\", \"log2\"],\n",
    "        \"clf__class_weight\": [None, \"balanced\"],\n",
    "    },\n",
    "    X_train, y_train, X_test, y_test\n",
    "))\n",
    "\n",
    "# Random Forest\n",
    "improved_results.append(tune_and_eval(\n",
    "    \"RandomForest\",\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1),\n",
    "    {\n",
    "        \"clf__n_estimators\": [300],\n",
    "        \"clf__max_depth\": [None, 8, 16],\n",
    "        \"clf__min_samples_leaf\": [1, 10, 50],\n",
    "        \"clf__class_weight\": [None, \"balanced_subsample\"],\n",
    "    },\n",
    "    X_train, y_train, X_test, y_test\n",
    "))\n",
    "\n",
    "# XGBoost\n",
    "improved_results.append(tune_and_eval(\n",
    "    \"XGBoost\",\n",
    "    XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss'),\n",
    "    {\n",
    "        \"clf__n_estimators\": [100, 200, 300],\n",
    "        \"clf__max_depth\": [4, 6, 8],\n",
    "        \"clf__learning_rate\": [0.01, 0.1, 0.3],\n",
    "        \"clf__subsample\": [0.8, 1.0],\n",
    "        \"clf__colsample_bytree\": [0.8, 1.0],\n",
    "        \n",
    "        # use this instead if XGBoost is performing quickly enough to add more params\n",
    "        # \"clf__n_estimators\": [200, 400],\n",
    "        # \"clf__max_depth\": [4, 6, 8],\n",
    "        # \"clf__learning_rate\": [0.01, 0.05, 0.1],\n",
    "        # \"clf__subsample\": [0.7, 0.8, 1.0],\n",
    "        # \"clf__colsample_bytree\": [0.7, 0.8, 1.0],\n",
    "        # \"clf__gamma\": [0, 1, 5],\n",
    "        # \"clf__reg_lambda\": [1, 5, 10],\n",
    "        # \"clf__reg_alpha\": [0, 0.1, 1],\n",
    "    },\n",
    "    X_train, y_train, X_test, y_test\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
