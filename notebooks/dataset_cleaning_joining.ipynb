{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f48736bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import zipfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3478f4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset A records: 1004991\n",
      "\n",
      "First few rows with geometry:\n",
      "       LAT       LON                   geometry\n",
      "0  34.2124 -118.4092  POINT (-118.4092 34.2124)\n",
      "1  34.1993 -118.4203  POINT (-118.4203 34.1993)\n",
      "2  34.1847 -118.4509  POINT (-118.4509 34.1847)\n",
      "3  34.0339 -118.3747  POINT (-118.3747 34.0339)\n",
      "4  33.9813 -118.4350   POINT (-118.435 33.9813)\n",
      "\n",
      "Missing lat values: 0\n",
      "Missing lon values: 0\n"
     ]
    }
   ],
   "source": [
    "# Load your Dataset A with lat/lon\n",
    "df_a = pd.read_csv(r\"C:\\Users\\kayle\\Desktop\\DTSC-3601\\Crime_Data_from_2020_to_Present(2)(1).csv\")  # or whatever your source is\n",
    "\n",
    "#Create geometry column from lat/lon - USING THE CORRECT COLUMN NAMES\n",
    "geometry = [Point(xy) for xy in zip(df_a['LON'], df_a['LAT'])]\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "gdf_a = gpd.GeoDataFrame(df_a, geometry=geometry, crs=\"EPSG:4326\")\n",
    "\n",
    "print(f\"Dataset A records: {len(gdf_a)}\")\n",
    "print(\"\\nFirst few rows with geometry:\")\n",
    "print(gdf_a[['LAT', 'LON', 'geometry']].head())\n",
    "\n",
    "# Check for any missing coordinates\n",
    "missing_lat = gdf_a['LAT'].isna().sum()\n",
    "missing_lon = gdf_a['LON'].isna().sum()\n",
    "print(f\"\\nMissing lat values: {missing_lat}\")\n",
    "print(f\"Missing lon values: {missing_lon}\")\n",
    "\n",
    "# Remove rows with missing coordinates if any exist\n",
    "if missing_lat > 0 or missing_lon > 0:\n",
    "    gdf_a = gdf_a.dropna(subset=['LAT', 'LON'])\n",
    "    print(f\"Records after removing missing coordinates: {len(gdf_a)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa8236f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP code boundaries downloaded and extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "def download_zipcode_boundaries():\n",
    "    \"\"\"Download just the ZIP code boundaries\"\"\"\n",
    "    zip_url = \"https://www2.census.gov/geo/tiger/TIGER2022/ZCTA520/tl_2022_us_zcta520.zip\"\n",
    "    filename = \"tl_2022_us_zcta520.zip\"\n",
    "    extract_path = \"./zipcode_boundaries\"\n",
    "    \n",
    "    # Create directory if it doesn't exist\n",
    "    os.makedirs(extract_path, exist_ok=True)\n",
    "    \n",
    "    # Download the file\n",
    "    response = requests.get(zip_url, stream=True)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        with open(filename, 'wb') as f:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                f.write(chunk)\n",
    "        \n",
    "        # Extract the zip file\n",
    "        with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "            zip_ref.extractall(extract_path)\n",
    "        \n",
    "        print(\"ZIP code boundaries downloaded and extracted successfully!\")\n",
    "        return extract_path\n",
    "    else:\n",
    "        print(f\"Failed to download. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Download ZIP code boundaries\n",
    "zip_path = download_zipcode_boundaries()\n",
    "\n",
    "if zip_path:\n",
    "    # Load the ZIP code boundaries\n",
    "    gdf_zcta = gpd.read_file(f\"{zip_path}/tl_2022_us_zcta520.shp\")\n",
    "else:\n",
    "    # If download fails, try loading from a manually downloaded file\n",
    "    manual_path = r\"C:\\Users\\kayle\\Desktop\\DTSC-3601\\zipcode_boundaries\"\n",
    "    if os.path.exists(f\"{manual_path}/tl_2022_us_zcta520.shp\"):\n",
    "        gdf_zcta = gpd.read_file(f\"{manual_path}/tl_2022_us_zcta520.shp\")\n",
    "    else:\n",
    "        print(\"Please manually download the ZIP code file and place it in zipcode_boundaries/ folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87cf0b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing spatial join with ZIP codes...\n",
      "Spatial join completed!\n",
      "Records matched to ZIP codes: 1002345\n",
      "Success rate: 99.74%\n",
      "\n",
      "ZIP code coverage:\n",
      "99.7% of crime records matched to ZIP codes\n"
     ]
    }
   ],
   "source": [
    "# Perform spatial join with ZIP codes\n",
    "print(\"Performing spatial join with ZIP codes...\")\n",
    "\n",
    "# Ensure same coordinate reference system\n",
    "gdf_zcta = gdf_zcta.to_crs(gdf_a.crs)\n",
    "\n",
    "# Perform the spatial join\n",
    "gdf_merged = gpd.sjoin(gdf_a, gdf_zcta, how='left', predicate='within')\n",
    "\n",
    "# Extract the ZIP code\n",
    "gdf_merged['zip_code'] = gdf_merged['ZCTA5CE20']\n",
    "\n",
    "print(f\"Spatial join completed!\")\n",
    "print(f\"Records matched to ZIP codes: {gdf_merged['zip_code'].notna().sum()}\")\n",
    "print(f\"Success rate: {gdf_merged['zip_code'].notna().sum() / len(gdf_merged):.2%}\")\n",
    "\n",
    "# Show some statistics\n",
    "print(f\"\\nZIP code coverage:\")\n",
    "zip_coverage = gdf_merged['zip_code'].notna().sum() / len(gdf_merged) * 100\n",
    "print(f\"{zip_coverage:.1f}% of crime records matched to ZIP codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1199852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged dataset saved to: C:\\Users\\kayle\\Desktop\\DTSC-3601\\crime_data_with_zipcodes.csv\n",
      "Final columns: ['DR_NO', 'Date Rptd', 'DATE OCC', 'TIME OCC', 'AREA', 'AREA NAME', 'Rpt Dist No', 'Part 1-2', 'Crm Cd', 'Crm Cd Desc', 'Mocodes', 'Vict Age', 'Vict Sex', 'Vict Descent', 'Premis Cd', 'Premis Desc', 'Weapon Used Cd', 'Weapon Desc', 'Status', 'Status Desc', 'Crm Cd 1', 'Crm Cd 2', 'Crm Cd 3', 'Crm Cd 4', 'LOCATION', 'Cross Street', 'LAT', 'LON', 'ZCTA5CE20', 'GEOID20', 'CLASSFP20', 'MTFCC20', 'FUNCSTAT20', 'ALAND20', 'AWATER20', 'INTPTLAT20', 'INTPTLON20', 'zip_code']\n",
      "Total records: 1004991\n",
      "Records with ZIP codes: 1002345\n",
      "\n",
      "Sample of merged data (first 10 rows):\n",
      "       LAT       LON zip_code\n",
      "0  34.2124 -118.4092    91605\n",
      "1  34.1993 -118.4203    91605\n",
      "2  34.1847 -118.4509    91411\n",
      "3  34.0339 -118.3747    90034\n",
      "4  33.9813 -118.4350    90292\n",
      "5  34.0830 -118.1678    90032\n",
      "6  34.0100 -118.2900    90037\n",
      "7  34.1107 -118.2589    90039\n",
      "8  34.2763 -118.5210    91344\n",
      "9  34.1493 -118.5886    91364\n"
     ]
    }
   ],
   "source": [
    "# Select final columns - keep all original columns plus the new zip_code\n",
    "final_columns = [col for col in gdf_merged.columns if col != 'geometry' and not col.startswith('index_')]\n",
    "final_columns.append('zip_code')  # Ensure zip_code is included\n",
    "\n",
    "# Remove any duplicate columns\n",
    "final_columns = list(dict.fromkeys(final_columns))\n",
    "\n",
    "# Create final dataframe\n",
    "df_final = gdf_merged[final_columns]\n",
    "\n",
    "# Save to CSV\n",
    "output_path = r\"C:\\Users\\kayle\\Desktop\\DTSC-3601\\crime_data_with_zipcodes.csv\"\n",
    "df_final.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\nMerged dataset saved to: {output_path}\")\n",
    "print(f\"Final columns: {list(df_final.columns)}\")\n",
    "print(f\"Total records: {len(df_final)}\")\n",
    "print(f\"Records with ZIP codes: {df_final['zip_code'].notna().sum()}\")\n",
    "\n",
    "# Show sample of results\n",
    "print(\"\\nSample of merged data (first 10 rows):\")\n",
    "sample_cols = ['LAT', 'LON', 'zip_code']\n",
    "# Add any other important columns from your original data\n",
    "for col in ['police_district', 'area_name', 'crime_type']:  # adjust to your actual column names\n",
    "    if col in df_final.columns:\n",
    "        sample_cols.append(col)\n",
    "\n",
    "print(df_final[sample_cols].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62617bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crime with zip columns: ['DR_NO', 'Date Rptd', 'DATE OCC', 'TIME OCC', 'AREA', 'AREA NAME', 'Rpt Dist No', 'Part 1-2', 'Crm Cd', 'Crm Cd Desc', 'Mocodes', 'Vict Age', 'Vict Sex', 'Vict Descent', 'Premis Cd', 'Premis Desc', 'Weapon Used Cd', 'Weapon Desc', 'Status', 'Status Desc', 'Crm Cd 1', 'Crm Cd 2', 'Crm Cd 3', 'Crm Cd 4', 'LOCATION', 'Cross Street', 'LAT', 'LON', 'ZCTA5CE20', 'GEOID20', 'CLASSFP20', 'MTFCC20', 'FUNCSTAT20', 'ALAND20', 'AWATER20', 'INTPTLAT20', 'INTPTLON20', 'zip_code']\n",
      "Sexual crimes columns: ['DR_NO', 'Date Rptd', 'DATE OCC', 'TIME OCC', 'AREA', 'AREA NAME', 'Rpt Dist No', 'Part 1-2', 'Crm Cd', 'Crm Cd Desc', 'Mocodes', 'Vict Age', 'Vict Sex', 'Vict Descent', 'Premis Cd', 'Premis Desc', 'Weapon Used Cd', 'Weapon Desc', 'Crm Cd 1', 'Crm Cd 2', 'Crm Cd 3', 'Crm Cd 4', 'Vict Descent Full', 'Vict Age Group', 'Time_Formatted', 'Hour', 'Time_Category', 'Date_Rptd', 'DATE_OCC', 'Year', 'Month', 'DayOfWeek', 'Reporting_Delay', 'Delay_Category']\n",
      "\n",
      "Crime with zip shape: (1004991, 38)\n",
      "Sexual crimes shape: (12371, 34)\n",
      "\n",
      "DR_NO unique in crime_with_zip: True\n",
      "DR_NO unique in sexual_crimes: True\n",
      "\n",
      "After merge shape: (12371, 35)\n",
      "Missing zip codes: 28\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load both datasets\n",
    "crime_with_zip = pd.read_csv(r\"C:\\Users\\kayle\\Desktop\\DTSC-3601\\Project\\crime_data_with_zipcodes.csv\")\n",
    "sexual_crimes = pd.read_csv(r\"C:\\Users\\kayle\\Downloads\\sexual_crimes_cleaned(1).csv\")\n",
    "\n",
    "# Check the structure of both datasets first\n",
    "print(\"Crime with zip columns:\", crime_with_zip.columns.tolist())\n",
    "print(\"Sexual crimes columns:\", sexual_crimes.columns.tolist())\n",
    "print(\"\\nCrime with zip shape:\", crime_with_zip.shape)\n",
    "print(\"Sexual crimes shape:\", sexual_crimes.shape)\n",
    "\n",
    "# Check if DR_NO is unique in both datasets\n",
    "print(\"\\nDR_NO unique in crime_with_zip:\", crime_with_zip['DR_NO'].nunique() == len(crime_with_zip))\n",
    "print(\"DR_NO unique in sexual_crimes:\", sexual_crimes['DR_NO'].nunique() == len(sexual_crimes))\n",
    "\n",
    "# Perform the left join to add zip_code to sexual_crimes dataset\n",
    "# We only select the DR_NO and zip_code columns from the crime_with_zip dataset\n",
    "sexual_crimes_with_zip = sexual_crimes.merge(\n",
    "    crime_with_zip[['DR_NO', 'zip_code']],  # Only bring these two columns\n",
    "    on='DR_NO', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Check the result\n",
    "print(\"\\nAfter merge shape:\", sexual_crimes_with_zip.shape)\n",
    "print(\"Missing zip codes:\", sexual_crimes_with_zip['zip_code'].isnull().sum())\n",
    "\n",
    "# Save the updated dataset\n",
    "sexual_crimes_with_zip.to_csv(r'C:\\Users\\kayle\\Downloads\\sexual_crimes_with_zip.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
